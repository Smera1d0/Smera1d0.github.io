<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>信息论 on Smera1d0&#39;s Blog</title>
    <link>http://localhost:1313/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/</link>
    <description>Recent content in 信息论 on Smera1d0&#39;s Blog</description>
    <image>
      <title>Smera1d0&#39;s Blog</title>
      <url>http://localhost:1313/images/papermod-cover.png</url>
      <link>http://localhost:1313/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <copyright>© [PaperMod Contributors](https://github.com/adityatelange/hugo-PaperMod/graphs/contributors)</copyright>
    <lastBuildDate>Sat, 16 Mar 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>信息论基础</title>
      <link>http://localhost:1313/posts/%E4%BF%A1%E6%81%AF%E8%AE%BA%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Sat, 16 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E4%BF%A1%E6%81%AF%E8%AE%BA%E5%9F%BA%E7%A1%80/</guid>
      <description>&lt;h2 id=&#34;熵相对熵与互信息&#34;&gt;熵、相对熵与互信息&lt;/h2&gt;
&lt;h3 id=&#34;熵&#34;&gt;熵&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：一个离散型随机变量 $X$ 的熵 $H(X)$ 定义为：
$$
H(X)=-\sum_{x \in X}p(x) \log p(x)
$$
&lt;strong&gt;注释&lt;/strong&gt;：$X$ 的熵又可以理解为随机变量 $\log \frac{1}{p(X)}$ 的期望值&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;引理&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$H(X) \geq 0$&lt;/li&gt;
&lt;li&gt;$H_b(X)=(\log_ba)H_a(X)$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;二元熵&lt;/strong&gt;：
$$
H(X)= -p\log p-(1-p)\log (1-p) \rightarrow H(p)
$$
$H(p)$ 为上凸函数，在 $p= \frac{1}{2}$ 时取得最大值 1&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
